{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing people v.0.1.0\n",
      "CUDA_VISIBLE_DEVICES not defined\n",
      "Using TensorFlow backend.\n",
      "/home/diogo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/diogo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/diogo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/diogo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/diogo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/diogo/.local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/diogo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/diogo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/diogo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/diogo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/diogo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/diogo/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using keras from \"/home/diogo/git/fchollet/keras\" version \"2.2.4\"\n",
      "\u001b[91mNo module named 'configobj'\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import people\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "from people.datasets import Human36M\n",
    "\n",
    "from people.evaluation import average_world_poses\n",
    "from people.evaluation import eval_human36m_activities\n",
    "\n",
    "from people.utils import *\n",
    "\n",
    "\n",
    "from people import datasetpath\n",
    "from people.datasets.human36m import ZBOUND\n",
    "from people.datasets.human36m import BBOX_REF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/storage/diogo/Datasets/Human3.6M'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetpath('Human3.6M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h36m = Human36M(datasetpath('Human3.6M'), DataConfig(), [(32, 32)],\n",
    "        image_div=8, poselayout=est34j3d, preprocess_mode='caffe')\n",
    "\n",
    "poselayout = est34j3d\n",
    "num_joints = poselayout.num_joints\n",
    "anchor_id = 0\n",
    "\n",
    "saveddir = 'output/pred_h36m_022_val'\n",
    "\n",
    "p0_h36m = np.load(os.path.join(saveddir, 'p_h36m_hf0.npy'))\n",
    "p1_h36m = np.load(os.path.join(saveddir, 'p_h36m_hf1.npy'))\n",
    "afmat0_h36m = np.load(os.path.join(saveddir, 'afmat_h36m_hf0.npy'))\n",
    "afmat1_h36m = np.load(os.path.join(saveddir, 'afmat_h36m_hf1.npy'))\n",
    "pred0_z = np.load(os.path.join(saveddir, 'pred_absz_hf0.npy'))\n",
    "pred1_z = np.load(os.path.join(saveddir, 'pred_absz_hf1.npy'))\n",
    "pred0_p = np.load(os.path.join(saveddir, 'pred_pose_hf0.npy'))\n",
    "pred1_p = np.load(os.path.join(saveddir, 'pred_pose_hf1.npy'))\n",
    "\n",
    "pw_h36m = np.load(os.path.join(saveddir, 'pw_h36m_hf0.npy'))\n",
    "rootz_h36m = np.load(os.path.join(saveddir, 'rootz_h36m_hf0.npy'))\n",
    "scam_h36m = np.load(os.path.join(saveddir, 'scam_h36m_hf0.npy'))\n",
    "action_h36m = np.load(os.path.join(saveddir, 'action_h36m_hf0.npy'))\n",
    "\n",
    "with open(os.path.join(saveddir, 'meta_hf0.json'), 'r') as fid:\n",
    "    meta_h36m = json.load(fid)\n",
    "\n",
    "p1_h36m = p1_h36m[:, :, poselayout.map_hflip, :]\n",
    "pred1_p = pred1_p[:, :, poselayout.map_hflip, :]\n",
    "\n",
    "pw_h36m = pw_h36m[:, h36m23j3d.map_to_pa17j, :]\n",
    "\n",
    "p0_h36m = p0_h36m[:, anchor_id, :, :3]\n",
    "p0_h36m = p0_h36m[:, poselayout.map_to_pa17j, :]\n",
    "p1_h36m = p1_h36m[:, anchor_id, :, :3]\n",
    "p1_h36m = p1_h36m[:, poselayout.map_to_pa17j, :]\n",
    "\n",
    "pred0_p = pred0_p[:, anchor_id, :, :3]\n",
    "pred0_p = pred0_p[:, poselayout.map_to_pa17j, :]\n",
    "pred1_p = pred1_p[:, anchor_id, :, :3]\n",
    "pred1_p = pred1_p[:, poselayout.map_to_pa17j, :]\n",
    "\n",
    "cameras = [camera_deserialize(c) for c in scam_h36m]\n",
    "rootz = rootz_h36m[:, anchor_id:anchor_id+1]*(ZBOUND[1] - ZBOUND[0]) + ZBOUND[0]\n",
    "\n",
    "pred0_z = pred0_z[:, anchor_id:anchor_id+1]*(ZBOUND[1] - ZBOUND[0]) + ZBOUND[0]\n",
    "pred1_z = pred1_z[:, anchor_id:anchor_id+1]*(ZBOUND[1] - ZBOUND[0]) + ZBOUND[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Err_e on GT poses projected to world:  0.12344697948330895\n",
      "Err_e on GT poses projected to camera:  0.12344697948330399\n",
      "ABS err on predicted poses using GT cameras: 89.47 mm\n",
      "REL err on predicted poses using GT cameras: 49.29 mm\n"
     ]
    }
   ],
   "source": [
    "# \"\"\"Sanity check.\"\"\"\n",
    "pose_w = inverse_project_pose_to_camera_ref(p0_h36m, rootz, afmat0_h36m,\n",
    "        cameras, resol_z=BBOX_REF, project_to_world=True)\n",
    "err_w = np.mean(np.sqrt(np.sum(\n",
    "                np.square(pw_h36m - pose_w), axis=-1)))\n",
    "print ('Err_e on GT poses projected to world: ', err_w)\n",
    "\n",
    "pose_c1 = inverse_project_pose_to_camera_ref(p0_h36m, rootz, afmat0_h36m,\n",
    "        cameras, resol_z=BBOX_REF, project_to_world=False)\n",
    "\n",
    "pose_c_gt = np.nan * np.ones(pw_h36m.shape)\n",
    "for i in range(len(pose_c_gt)):\n",
    "    pose_c_gt[i] = project_world2camera(cameras[i], pw_h36m[i])\n",
    "\n",
    "err_c = abs_mpjpe(pose_c1, pose_c_gt)\n",
    "print ('Err_e on GT poses projected to camera: ', err_c)\n",
    "\n",
    "\"\"\"Predictions using GT camera parameters.\"\"\"\n",
    "pred0_w = inverse_project_pose_to_camera_ref(pred0_p.copy(), pred0_z.copy(),\n",
    "            afmat0_h36m, cameras, resol_z=BBOX_REF, project_to_world=True)\n",
    "pred1_w = inverse_project_pose_to_camera_ref(pred1_p.copy(), pred1_z.copy(),\n",
    "            afmat1_h36m, cameras, resol_z=BBOX_REF, project_to_world=True)\n",
    "pred_w = (pred0_w + pred1_w) / 2.\n",
    "\n",
    "pred_c = np.nan * np.ones(pred_w.shape)\n",
    "for i in range(len(pred_c)):\n",
    "    pred_c[i] = project_world2camera(cameras[i], pred_w[i])\n",
    "\n",
    "err_pred = abs_mpjpe(pred_c, pose_c_gt)\n",
    "print ('ABS err on predicted poses using GT cameras: %.2f mm' % err_pred)\n",
    "\n",
    "err_pred = rel_mpjpe(pred_c, pose_c_gt)\n",
    "print ('REL err on predicted poses using GT cameras: %.2f mm' % err_pred)\n",
    "\n",
    "puvd0 = pred0_p.copy()\n",
    "puvd0[:, :, 0:2] = transform_pose_sequence(afmat0_h36m.copy(), puvd0[:, :, 0:2],\n",
    "        inverse=True)\n",
    "puvd0[:, :, 2] = BBOX_REF * (puvd0[:, :, 2] - 0.5) + pred0_z\n",
    "\n",
    "puvd1 = pred1_p.copy()\n",
    "puvd1[:, :, 0:2] = transform_pose_sequence(afmat1_h36m.copy(), puvd1[:, :, 0:2],\n",
    "        inverse=True)\n",
    "puvd1[:, :, 2] = BBOX_REF * (puvd1[:, :, 2] - 0.5) + pred1_z\n",
    "\n",
    "puvd = (puvd0 + puvd1) / 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results not considering the lens distortion coefficients:\n",
      "ABS err on predicted poses using est. cameras: 90.08 mm\n",
      "REL err on predicted poses using est. cameras: 50.01 mm\n"
     ]
    }
   ],
   "source": [
    "pc_gtcam = np.zeros(puvd.shape)\n",
    "for i in range(len(puvd)):\n",
    "    pc_gtcam[i] = camera_inv_proj(puvd[i],\n",
    "            cameras[i].f[0,0], cameras[i].f[0,1],\n",
    "            cameras[i].c[0,0], cameras[i].c[0,1])\n",
    "\n",
    "print ('Results not considering the lens distortion coefficients:')\n",
    "\n",
    "err_pred = abs_mpjpe(pc_gtcam, pose_c_gt)\n",
    "print ('ABS err on predicted poses using est. cameras: %.2f mm' % err_pred)\n",
    "\n",
    "err_pred = rel_mpjpe(pc_gtcam, pose_c_gt)\n",
    "print ('REL err on predicted poses using est. cameras: %.2f mm' % err_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_mpjpe(p1, p2):\n",
    "    return np.std(np.sqrt(np.sum(np.square(p1 - p2), axis=-1)))\n",
    "\n",
    "def dist_mpjpe(p1, p2):\n",
    "    return np.sqrt(np.sum(np.square(p1 - p2), axis=-1))\n",
    "\n",
    "def predict_camera_parameters(puvd1, puvd2, miniter=100, maxiter=600,\n",
    "        alpha=0.8, f_init=500, c_init=500):\n",
    "\n",
    "    assert puvd1.shape == puvd2.shape, \\\n",
    "        'Incompatible pose shapes {},{}'.format(puvd1.shape, puvd2.shape)\n",
    "    \n",
    "    # Initialize variables\n",
    "    f1 = np.array([[f_init, f_init]])\n",
    "    f2 = np.array([[f_init, f_init]])\n",
    "    c1 = np.array([[c_init, c_init]])\n",
    "    c2 = np.array([[c_init, c_init]])\n",
    "\n",
    "    pc1 = predict_xy_mm(puvd1, f1, c1)\n",
    "    pc2 = predict_xy_mm(puvd2, f2, c2)\n",
    "\n",
    "    X1 = pc1\n",
    "    X2 = np.concatenate([pc2, np.ones((len(pc2), 1))], axis=-1)\n",
    "    P21_init = getP(X2, X1)\n",
    "\n",
    "    pc1_init = project_poses(pc2, P21_init)\n",
    "    t2 = -np.matmul(np.linalg.inv(P21_init[:,:3]), P21_init[:,3:4])\n",
    "    loss = []\n",
    "    prev_loss = 1e4\n",
    "    min_loss = 1e4\n",
    "    \n",
    "    spl = range(len(puvd1))\n",
    "\n",
    "    for i in range(maxiter):\n",
    "        puvd1_b = puvd1[spl]\n",
    "        puvd2_b = puvd2[spl]\n",
    "        pc1_b = pc1[spl]\n",
    "        pc2_b = pc2[spl]\n",
    "        \n",
    "        R21 = kabsch_alignment(pc2_b - t2.T, pc1_b)\n",
    "        t2 = optimize_translation(pc2_b, pc1_b, R21)\n",
    "        R12 = np.linalg.inv(R21)\n",
    "        t1 = -np.matmul(R21, t2)\n",
    "\n",
    "        P21 = np.concatenate([R21, t1], axis=-1)\n",
    "        P12 = np.concatenate([R12, t2], axis=-1)\n",
    "\n",
    "        if i % 4 == 0:\n",
    "            f1 = optimize_focal(puvd1_b, pc2_b, P21, c1)\n",
    "            f1[0,0] = alpha*f1[0,0] + (1-alpha)*f1[0,1]\n",
    "            f1[0,1] = (1-alpha)*f1[0,0] + alpha*f1[0,1]\n",
    "\n",
    "        elif i % 4 == 1:\n",
    "            f2 = optimize_focal(puvd2_b, pc1_b, P12, c2)\n",
    "            f2[0,0] = alpha*f2[0,0] + (1-alpha)*f2[0,1]\n",
    "            f2[0,1] = (1-alpha)*f2[0,0] + alpha*f2[0,1]\n",
    "\n",
    "        elif i % 4 == 2:\n",
    "            c1 = optimize_center(puvd1_b, pc2_b, P21, f1)\n",
    "            c1[0,0] = alpha*c1[0,0] + (1-alpha)*c1[0,1]\n",
    "            c1[0,1] = (1-alpha)*c1[0,0] + alpha*c1[0,1]\n",
    "\n",
    "        elif i % 4 == 3:\n",
    "            c2 = optimize_center(puvd2_b, pc1_b, P12, f2)\n",
    "            c2[0,0] = alpha*c2[0,0] + (1-alpha)*c2[0,1]\n",
    "            c2[0,1] = (1-alpha)*c2[0,0] + alpha*c2[0,1]\n",
    "        \n",
    "        pc1 = predict_xy_mm(puvd1, f1, c1)\n",
    "        pc2 = predict_xy_mm(puvd2, f2, c2)\n",
    "\n",
    "        pc2c1 = project_poses(pc2, P21)\n",
    "        err = abs_mpjpe(pc2c1, pc1)\n",
    "        std = std_mpjpe(pc2c1, pc1)\n",
    "        dist = dist_mpjpe(pc2c1, pc1)\n",
    "        spl = dist < err + 2*std\n",
    "        loss.append(err)\n",
    "\n",
    "        if i > miniter and (loss[-1] > prev_loss or loss[-1] > min_loss + 1):\n",
    "            break\n",
    "\n",
    "        prev_loss = 0.5*prev_loss + 0.5*loss[-1]\n",
    "        if loss[-1] < min_loss:\n",
    "            min_loss = loss[-1]\n",
    "            f1o = f1.copy()\n",
    "            c1o = c1.copy()\n",
    "            f2o = f2.copy()\n",
    "            c2o = c2.copy()\n",
    "            P21o = P21.copy()\n",
    "            P12o = P12.copy()\n",
    "\n",
    "    return f1o, c1o, f2o, c2o, P21o, P12o, np.array(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! Sample 2 11 2 2 empty!\n",
      "Warning! Sample 2 11 2 3 empty!\n",
      "Warning! Sample 2 11 2 4 empty!\n",
      "114.92414622073764 43.528605876429474\n"
     ]
    }
   ],
   "source": [
    "cam_to_use = [1, 2, 3, 4]\n",
    "pose_c_pred = np.zeros(pose_c_gt.shape)\n",
    "alpha = 1 / len(cam_to_use)\n",
    "\n",
    "e1_list = []\n",
    "e2_list = []\n",
    "\n",
    "i = 0\n",
    "while i < len(pose_c_pred):\n",
    "    a, s, e, c, f = meta_h36m[i]\n",
    "    #print (a, s, e, c, f)\n",
    "\n",
    "    idxs = {}\n",
    "    for ic in range(4):\n",
    "        idxs[ic+1] = get_idxs_sequence(meta_h36m, asec=(a, s, e, ic+1))\n",
    "\n",
    "    try:\n",
    "        pairlist = cam_to_use.copy()\n",
    "        del pairlist[pairlist.index(c)]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    puvd1 = puvd[idxs[c]]\n",
    "    cam1 = cameras[idxs[c][0]]\n",
    "    if len(puvd1) == 0:\n",
    "        print ('Warning! Sample %d %d %d %d empty!' % (a, s, e, c))\n",
    "        continue\n",
    "    num_samples, num_joints, dim = puvd1.shape\n",
    "    pc_est = np.zeros((num_samples * num_joints, dim))\n",
    "\n",
    "    for pc in pairlist:\n",
    "        puvd2 = puvd[idxs[pc]]\n",
    "        if len(puvd2) == 0:\n",
    "            print ('Warning! Sample %d %d %d %d empty!' % (a, s, e, c))\n",
    "            continue\n",
    "\n",
    "        puvd1 = np.reshape(puvd1, (num_samples * num_joints, dim))\n",
    "        puvd2 = np.reshape(puvd2, (num_samples * num_joints, dim))\n",
    "\n",
    "        cam2 = cameras[idxs[pc][0]]\n",
    "\n",
    "        t2cam1 = np.matmul(cam1.R, cam2.t-cam1.t)\n",
    "        t1cam2 = np.matmul(cam2.R, cam1.t-cam2.t)\n",
    "\n",
    "        #print (t2cam1.T)\n",
    "        #print (t1cam2.T)\n",
    "\n",
    "        f1, c1, f2, c2, P21, P12, loss = predict_camera_parameters(puvd1, puvd2)\n",
    "        #print (f1, c1, f2, c2)\n",
    "        #plt.plot(loss)\n",
    "\n",
    "        #print ('t1', t1_est)\n",
    "        #print ('t2', t2_est)\n",
    "        e1 = abs_mpjpe(t2cam1, P21[:, -1:])\n",
    "        e2 = abs_mpjpe(t1cam2, P12[:, -1:])\n",
    "        #print (e1, e2)\n",
    "        e1_list.append(e1)\n",
    "        e2_list.append(e2)\n",
    "\n",
    "        pc1_est = predict_xy_mm(puvd1, f1, c1)\n",
    "        pc2_est = predict_xy_mm(puvd2, f2, c2)\n",
    "        pc_est += alpha * pc1_est + (1 - alpha) * project_poses(pc2_est, P21)\n",
    "\n",
    "    pc_est /= len(pairlist)\n",
    "    #pc_gt = pose_c_gt[idxs[c]]\n",
    "    #print (abs_mpjpe(pc_est, pc_gt), rel_mpjpe(pc_est, pc_gt))\n",
    "\n",
    "    pc_est = np.reshape(pc_est, (num_samples, num_joints, dim))\n",
    "    pose_c_pred[i:i+len(pc_est), :, :] = pc_est\n",
    "    i += len(pc_est)\n",
    "\n",
    "\"\"\"Removing empty sequences\"\"\"\n",
    "for c in range(4):\n",
    "    idxs = get_idxs_sequence(meta_h36m, asec=(2, 11, 2, c+1))\n",
    "    pose_c_pred[idxs] = 0\n",
    "    pose_c_gt[idxs] = 0\n",
    "\n",
    "print (abs_mpjpe(pose_c_pred, pose_c_gt), rel_mpjpe(pose_c_pred, pose_c_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179.5698924844859\n",
      "188.07815776346024\n"
     ]
    }
   ],
   "source": [
    "print (np.array(e1_list).mean())\n",
    "print (np.array(e2_list).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mDirections: 55.9\u001b[0m\n",
      "\u001b[94mDiscussion: 38.2\u001b[0m\n",
      "\u001b[94mEating: 39.0\u001b[0m\n",
      "\u001b[94mGreeting: 39.8\u001b[0m\n",
      "\u001b[94mPhoning: 42.0\u001b[0m\n",
      "\u001b[94mPosing: 39.5\u001b[0m\n",
      "\u001b[94mPurchases: 41.2\u001b[0m\n",
      "\u001b[94mSitting: 67.5\u001b[0m\n",
      "\u001b[94mSittingDown: 73.4\u001b[0m\n",
      "\u001b[94mSmoking: 42.5\u001b[0m\n",
      "\u001b[94mTakingPhoto: 45.1\u001b[0m\n",
      "\u001b[94mWaiting: 40.3\u001b[0m\n",
      "\u001b[94mWalking: 31.6\u001b[0m\n",
      "\u001b[94mWalkingDog: 41.2\u001b[0m\n",
      "\u001b[94mWalkingTogether: 35.8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from people.evaluation import eval_human36m_activities\n",
    "\n",
    "pose_c_pred -= pose_c_pred[:, 0:1, :]\n",
    "pose_c_gt -= pose_c_gt[:, 0:1, :]\n",
    "eval_human36m_activities(pose_c_pred, pose_c_gt, action_h36m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.97586790345391 25.97586790345391\n",
      "37.16420227842113 37.16420227842113\n",
      "44.85988945268579 44.85988945268579\n"
     ]
    }
   ],
   "source": [
    "prev_pred = np.load('pred_h36m_val_022d_079_multicam.npy')\n",
    "\n",
    "print (abs_mpjpe(pose_c_pred, prev_pred), rel_mpjpe(pose_c_pred, prev_pred))\n",
    "print (abs_mpjpe(pose_c_gt, prev_pred), rel_mpjpe(pose_c_gt, prev_pred))\n",
    "print (abs_mpjpe(pose_c_gt, pose_c_pred), rel_mpjpe(pose_c_gt, pose_c_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1226.53096709 1219.08934032]] [[506.17564355 506.03946699]] [[1189.75552262 1193.81291648]] [[475.25246835 475.64904758]]\n",
      "47.95568630519882\n",
      "58.93679194125264\n",
      "54.012748533452196\n",
      "499 55.24608504313956 55.24608504313956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diogo/.local/lib/python3.7/site-packages/matplotlib/font_manager.py:1241: UserWarning: findfont: Font family ['serif'] not found. Falling back to DejaVu Sans.\n",
      "  (prop.get_family(), self.defaultFamily[fontext]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Load poses in uvd format for a set of cameras.\"\"\"\n",
    "idxs1 = get_idxs_sequence(meta_h36m, (2, 9, 1, 1))\n",
    "idxs2 = get_idxs_sequence(meta_h36m, (2, 9, 1, 3))\n",
    "\n",
    "#idxs1 = idxs1[0:1]\n",
    "#idxs2 = idxs2[0:1]\n",
    "\n",
    "puvd1 = puvd[idxs1]\n",
    "puvd2 = puvd[idxs2]\n",
    "pc1_gt = pose_c_gt[idxs1]\n",
    "pc2_gt = pose_c_gt[idxs2]\n",
    "\n",
    "\n",
    "num_samples, num_joints, dim = puvd1.shape\n",
    "puvd1 = np.reshape(puvd1, (num_samples * num_joints, dim))\n",
    "puvd2 = np.reshape(puvd2, (num_samples * num_joints, dim))\n",
    "\n",
    "\n",
    "f1, c1, f2, c2, P21, P12, loss = predict_camera_parameters(puvd1, puvd2, 100, 500)\n",
    "print (f1, c1, f2, c2)\n",
    "pc1_cal = predict_xy_mm(puvd1, cameras[idxs1[0]].f, cameras[idxs1[0]].c)\n",
    "pc1_est = predict_xy_mm(puvd1, f1, c1)\n",
    "\n",
    "pc1_cal = np.reshape(pc1_cal, (num_samples, num_joints, dim))\n",
    "pc1_est = np.reshape(pc1_est, (num_samples, num_joints, dim))\n",
    "\n",
    "print (rel_mpjpe(pc1_gt, pc1_cal))\n",
    "print (rel_mpjpe(pc1_gt, pc1_est))\n",
    "\n",
    "pc2_est = predict_xy_mm(puvd2, f2, c2)\n",
    "pc2_est = project_poses(pc2_est, P21)\n",
    "\n",
    "pc2_est = np.reshape(pc2_est, (num_samples, num_joints, dim))\n",
    "pc1_est = (pc1_est + pc2_est) / 2.\n",
    "\n",
    "print (rel_mpjpe(pc1_gt, pc1_est))\n",
    "\n",
    "plt.plot(loss)\n",
    "print (np.argmin(loss), loss.min(), loss[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
